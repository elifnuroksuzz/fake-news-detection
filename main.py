"""
main.py
Fake News Detection - Ana Pipeline
TÃ¼m sÃ¼reÃ§leri koordine eden ana dosya
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional
import warnings
warnings.filterwarnings('ignore')

# src modÃ¼llerini import et
sys.path.append('src')

from data_preprocessing import DataPreprocessor
from feature_engineering import FeatureEngineering
from model_training import ModelTrainer
from model_evaluation import ModelEvaluator
from utils import (
    ConfigManager, setup_reproducibility, print_system_info,
    Logger, FileManager, ModelPersistence
)

class FakeNewsDetectionPipeline:
    """
    Tam fake news detection pipeline'Ä±
    """
    
    def __init__(self, config_path: str = "config.yaml"):
        """
        Pipeline baÅŸlatÄ±cÄ±sÄ±
        
        Args:
            config_path: KonfigÃ¼rasyon dosyasÄ± yolu
        """
        self.config = ConfigManager.load_config(config_path)
        
        # Logger baÅŸlat
        log_file = self.config.get('output', {}).get('log_file', 'fake_news_detection.log')
        self.logger = Logger(log_file)
        
        # Reproducibility ayarla
        seed = self.config.get('reproducibility', {}).get('random_seed', 42)
        setup_reproducibility(seed)
        
        # ModÃ¼lleri baÅŸlat
        self.preprocessor = DataPreprocessor(config_path)
        self.feature_engineer = FeatureEngineering(self.config)
        self.model_trainer = ModelTrainer(self.config)
        self.model_evaluator = ModelEvaluator(self.config)
        
        # SonuÃ§ kayÄ±t yollarÄ±
        self.model_save_path = self.config.get('models', {}).get('model_save_path', 'models/trained_models/')
        
        self.logger.log("ğŸš€ FakeNewsDetectionPipeline baÅŸlatÄ±ldÄ±!")
        
    def run_full_pipeline(self, force_preprocessing: bool = False,
                         force_feature_engineering: bool = False) -> bool:
        """
        Tam pipeline'Ä± Ã§alÄ±ÅŸtÄ±r
        
        Args:
            force_preprocessing: Veri Ã¶n iÅŸlemeyi zorla
            force_feature_engineering: Feature engineering'i zorla
            
        Returns:
            bool: Pipeline baÅŸarÄ±lÄ± mÄ±
        """
        self.logger.log("ğŸš€ TAM FAKE NEWS DETECTION PIPELINE BAÅLATILIYOR!")
        print("=" * 80)
        
        try:
            # 1. Veri Ã–n Ä°ÅŸleme
            success = self._run_preprocessing_stage(force_preprocessing)
            if not success:
                return False
                
            # 2. Feature Engineering
            success = self._run_feature_engineering_stage(force_feature_engineering)
            if not success:
                return False
                
            # 3. Model Training
            success = self._run_training_stage()
            if not success:
                return False
                
            # 4. Model Evaluation
            success = self._run_evaluation_stage()
            if not success:
                return False
                
            # 5. Final Report
            self._create_final_report()
            
            self.logger.log("ğŸ‰ TAM PIPELINE BAÅARIYLA TAMAMLANDI!")
            return True
            
        except Exception as e:
            self.logger.log(f"âŒ Pipeline hatasÄ±: {str(e)}", "ERROR")
            return False
    
    def _run_preprocessing_stage(self, force: bool = False) -> bool:
        """
        Veri Ã¶n iÅŸleme aÅŸamasÄ±
        
        Args:
            force: Zorla Ã§alÄ±ÅŸtÄ±r
            
        Returns:
            bool: BaÅŸarÄ±lÄ± mÄ±
        """
        self.logger.log("ğŸ“Š AÅAMA 1: VERÄ° Ã–N Ä°ÅLEME")
        print("\n" + "="*50)
        print("ğŸ“Š AÅAMA 1: VERÄ° Ã–N Ä°ÅLEME")
        print("="*50)
        
        # Ä°ÅŸlenmiÅŸ veri var mÄ± kontrol et
        processed_path = self.config['data']['processed_data_path']
        train_file = os.path.join(processed_path, 'train_processed.pkl')
        
        if os.path.exists(train_file) and not force:
            self.logger.log("âœ… Ä°ÅŸlenmiÅŸ veri mevcut, Ã¶n iÅŸleme atlaniyor")
            print("âœ… Ä°ÅŸlenmiÅŸ veri mevcut, Ã¶n iÅŸleme atlanÄ±yor")
            return True
        
        # Veri Ã¶n iÅŸlemeyi Ã§alÄ±ÅŸtÄ±r
        success = self.preprocessor.run_full_preprocessing()
        
        if success:
            self.logger.log("âœ… Veri Ã¶n iÅŸleme tamamlandÄ±")
            return True
        else:
            self.logger.log("âŒ Veri Ã¶n iÅŸleme baÅŸarÄ±sÄ±z", "ERROR")
            return False
    
    def _run_feature_engineering_stage(self, force: bool = False) -> bool:
        """
        Feature engineering aÅŸamasÄ±
        
        Args:
            force: Zorla Ã§alÄ±ÅŸtÄ±r
            
        Returns:
            bool: BaÅŸarÄ±lÄ± mÄ±
        """
        self.logger.log("ğŸ”§ AÅAMA 2: FEATURE ENGÄ°NEERÄ°NG")
        print("\n" + "="*50)
        print("ğŸ”§ AÅAMA 2: FEATURE ENGÄ°NEERÄ°NG")
        print("="*50)
        
        # Feature dosyasÄ± var mÄ± kontrol et
        processed_path = self.config['data']['processed_data_path']
        features_file = os.path.join(processed_path, 'features_ready.pkl')
        
        if os.path.exists(features_file) and not force:
            self.logger.log("âœ… Feature'lar mevcut, feature engineering atlanÄ±yor")
            print("âœ… Feature'lar mevcut, feature engineering atlanÄ±yor")
            
            # Mevcut feature'larÄ± yÃ¼kle
            import pickle
            with open(features_file, 'rb') as f:
                feature_data = pickle.load(f)
            self.features = feature_data['features']
            self.feature_names = feature_data['feature_names']
            return True
        
        try:
            # Ä°ÅŸlenmiÅŸ veriyi yÃ¼kle
            processed_path = self.config['data']['processed_data_path']
            
            self.logger.log("ğŸ“¥ Ä°ÅŸlenmiÅŸ veriler yÃ¼kleniyor...")
            train_df = pd.read_pickle(os.path.join(processed_path, 'train_processed.pkl'))
            valid_df = pd.read_pickle(os.path.join(processed_path, 'valid_processed.pkl'))
            test_df = pd.read_pickle(os.path.join(processed_path, 'test_processed.pkl'))
            
            print(f"ğŸ“Š Veri boyutlarÄ±:")
            print(f"   Train: {train_df.shape}")
            print(f"   Valid: {valid_df.shape}")
            print(f"   Test: {test_df.shape}")
            
            # Feature engineering Ã§alÄ±ÅŸtÄ±r
            self.logger.log("ğŸ”§ Feature engineering baÅŸlatÄ±lÄ±yor...")
            self.features = self.feature_engineer.create_all_features(train_df, valid_df, test_df)
            
            # Feature isimlerini al
            self.feature_names = self.feature_engineer.get_feature_names()
            
            # Feature'larÄ± kaydet
            feature_data = {
                'features': self.features,
                'feature_names': self.feature_names
            }
            
            FileManager.save_pickle(feature_data, features_file)
            
            self.logger.log("âœ… Feature engineering tamamlandÄ±")
            return True
            
        except Exception as e:
            self.logger.log(f"âŒ Feature engineering hatasÄ±: {str(e)}", "ERROR")
            return False
    
    def _run_training_stage(self) -> bool:
        """
        Model eÄŸitimi aÅŸamasÄ±
        
        Returns:
            bool: BaÅŸarÄ±lÄ± mÄ±
        """
        self.logger.log("ğŸ¤– AÅAMA 3: MODEL EÄÄ°TÄ°MÄ°")
        print("\n" + "="*50)
        print("ğŸ¤– AÅAMA 3: MODEL EÄÄ°TÄ°MÄ°")
        print("="*50)
        
        try:
            # Training data hazÄ±rla
            X_train = self.features['X_train']
            y_train = self.features['y_train']
            
            self.logger.log(f"ğŸ“Š Training veri boyutu: {X_train.shape}")
            
            # TÃ¼m modelleri eÄŸit
            self.training_results = self.model_trainer.train_all_models(X_train, y_train)
            
            if not self.training_results:
                self.logger.log("âŒ HiÃ§bir model eÄŸitilemedi", "ERROR")
                return False
            
            # En iyi modeli al
            self.best_model, self.best_model_name = self.model_trainer.get_best_model()
            
            # Modelleri kaydet
            self.model_trainer.save_models(self.model_save_path)
            
            self.logger.log("âœ… Model eÄŸitimi tamamlandÄ±")
            self.logger.log(f"ğŸ† En iyi model: {self.best_model_name}")
            
            return True
            
        except Exception as e:
            self.logger.log(f"âŒ Model eÄŸitimi hatasÄ±: {str(e)}", "ERROR")
            return False
    
    def _run_evaluation_stage(self) -> bool:
        """
        Model deÄŸerlendirme aÅŸamasÄ±
        
        Returns:
            bool: BaÅŸarÄ±lÄ± mÄ±
        """
        self.logger.log("ğŸ“Š AÅAMA 4: MODEL DEÄERLENDÄ°RME")
        print("\n" + "="*50)
        print("ğŸ“Š AÅAMA 4: MODEL DEÄERLENDÄ°RME")
        print("="*50)
        
        try:
            # Test data hazÄ±rla
            X_test = self.features['X_test']
            y_test = self.features['y_test']
            
            self.logger.log(f"ğŸ“Š Test veri boyutu: {X_test.shape}")
            
            # EÄŸitilmiÅŸ modelleri al
            trained_models = self.model_trainer.best_models
            
            # TÃ¼m modelleri deÄŸerlendir
            self.evaluation_results = self.model_evaluator.evaluate_multiple_models(
                trained_models, X_test, y_test, self.feature_names
            )
            
            # DeÄŸerlendirme raporunu kaydet
            self.model_evaluator.save_evaluation_report(
                self.evaluation_results, "final_evaluation_report"
            )
            
            self.logger.log("âœ… Model deÄŸerlendirme tamamlandÄ±")
            
            return True
            
        except Exception as e:
            self.logger.log(f"âŒ Model deÄŸerlendirme hatasÄ±: {str(e)}", "ERROR")
            return False
    
    def _create_final_report(self):
        """
        Final rapor oluÅŸtur
        """
        self.logger.log("ğŸ“„ FINAL RAPOR OLUÅTURULUYOR")
        print("\n" + "="*50)
        print("ğŸ“„ FINAL RAPOR")
        print("="*50)
        
        # En iyi model bilgileri
        print(f"ğŸ† EN Ä°YÄ° MODEL: {self.best_model_name}")
        
        if self.best_model_name in self.evaluation_results:
            best_metrics = self.evaluation_results[self.best_model_name]['metrics']
            
            print(f"\nğŸ“Š EN Ä°YÄ° MODEL PERFORMANSI:")
            print(f"   ğŸ¯ Accuracy:  {best_metrics['accuracy']:.4f}")
            print(f"   ğŸ” Precision: {best_metrics['precision']:.4f}")
            print(f"   ğŸ“ˆ Recall:    {best_metrics['recall']:.4f}")
            print(f"   âš–ï¸ F1-Score:  {best_metrics['f1_score']:.4f}")
            
            if 'roc_auc' in best_metrics:
                print(f"   ğŸ“Š ROC-AUC:   {best_metrics['roc_auc']:.4f}")
        
        # Dosya konumlarÄ±
        print(f"\nğŸ“ OLUÅTURULAN DOSYALAR:")
        print(f"   ğŸ¤– Modeller: {self.model_save_path}")
        print(f"   ğŸ“Š Grafikler: {self.config.get('output', {}).get('figures_path', 'results/figures/')}")
        print(f"   ğŸ“„ Raporlar: {self.config.get('output', {}).get('reports_path', 'results/reports/')}")
        
        # Ã–zet istatistikler
        total_models = len(self.training_results) if hasattr(self, 'training_results') else 0
        print(f"\nğŸ“ˆ Ã–ZET Ä°STATÄ°STÄ°KLER:")
        print(f"   ğŸ¤– EÄŸitilen model sayÄ±sÄ±: {total_models}")
        print(f"   ğŸ“Š Toplam veri Ã¶rneÄŸi: {self.features['X_train'].shape[0] + self.features['X_test'].shape[0]}")
        print(f"   ğŸ”¢ Ã–zellik sayÄ±sÄ±: {self.features['X_train'].shape[1]}")
        
        self.logger.log("âœ… Final rapor oluÅŸturuldu")
        
        print("\nğŸ‰ FAKE NEWS DETECTION PIPELINE TAMAMLANDI!")
        print("="*80)
    
    def predict(self, text: str) -> Dict:
        """
        Tek bir metin iÃ§in tahmin yap
        
        Args:
            text: Tahmin yapÄ±lacak metin
            
        Returns:
            Dict: Tahmin sonucu
        """
        if not hasattr(self, 'best_model'):
            raise ValueError("Pipeline henÃ¼z Ã§alÄ±ÅŸtÄ±rÄ±lmadÄ±!")
        
        # Metni iÅŸle
        processed_text = self.preprocessor.clean_text(text)
        tokens = self.preprocessor.tokenize_and_filter(processed_text)
        
        # Dummy DataFrame oluÅŸtur (feature engineering iÃ§in)
        dummy_df = pd.DataFrame({
            'cleaned_statement': [processed_text],
            'tokens': [tokens],
            'subject': ['unknown'],
            'party_affiliation': ['unknown'],
            'state_info': ['unknown'],
            'barely_true_counts': [0],
            'false_counts': [0],
            'half_true_counts': [0],
            'mostly_true_counts': [0],
            'pants_on_fire_counts': [0]
        })
        
        # Feature'larÄ± Ã§Ä±kar (sadece istatistiksel ve metadata)
        stat_features = self.feature_engineer.create_statistical_features(dummy_df)
        meta_features = self.feature_engineer.create_metadata_features(dummy_df)
        
        # TF-IDF features
        text_for_tfidf = ' '.join(tokens)
        tfidf_features = self.feature_engineer.tfidf_vectorizer.transform([text_for_tfidf])
        
        # TÃ¼m feature'larÄ± birleÅŸtir
        combined_features = self.feature_engineer.combine_features(
            tfidf_features.toarray(), stat_features, meta_features
        )
        
        # Ã–lÃ§eklendir
        if combined_features.shape[1] > self.feature_engineer.max_features:
            tfidf_part = combined_features[:, :self.feature_engineer.max_features]
            other_part = combined_features[:, self.feature_engineer.max_features:]
            other_part_scaled = self.feature_engineer.scaler.transform(other_part)
            combined_features = np.hstack([tfidf_part, other_part_scaled])
        
        # Tahmin yap
        prediction = self.best_model.predict(combined_features)[0]
        
        # Probability (varsa)
        if hasattr(self.best_model, 'predict_proba'):
            probabilities = self.best_model.predict_proba(combined_features)[0]
            fake_prob = probabilities[0]
            real_prob = probabilities[1]
        else:
            fake_prob = 1 - prediction
            real_prob = prediction
        
        result = {
            'prediction': 'Real' if prediction == 1 else 'Fake',
            'confidence': max(fake_prob, real_prob),
            'probabilities': {
                'fake': fake_prob,
                'real': real_prob
            },
            'processed_text': processed_text,
            'token_count': len(tokens)
        }
        
        return result

def main():
    """Ana fonksiyon"""
    print("ğŸš€ FAKE NEWS DETECTION SYSTEM")
    print("=" * 80)
    
    # Sistem bilgilerini gÃ¶ster
    print_system_info()
    print()
    
    # Pipeline'Ä± baÅŸlat
    pipeline = FakeNewsDetectionPipeline("config.yaml")
    
    # Tam pipeline'Ä± Ã§alÄ±ÅŸtÄ±r
    success = pipeline.run_full_pipeline()
    
    if success:
        print("\nâœ… PIPELINE BAÅARIYLA TAMAMLANDI!")
        
        # Demo tahmin
        print("\nğŸ§ª DEMO TAHMÄ°N TESTÄ°")
        print("-" * 30)
        
        sample_texts = [
            "The president announced new economic policies yesterday.",
            "Scientists have discovered aliens living in underground cities!",
            "The stock market experienced significant volatility this week."
        ]
        
        for i, text in enumerate(sample_texts, 1):
            print(f"\n{i}. Metin: {text}")
            try:
                result = pipeline.predict(text)
                print(f"   ğŸ“Š Tahmin: {result['prediction']}")
                print(f"   ğŸ¯ GÃ¼ven: {result['confidence']:.3f}")
                print(f"   ğŸ“ˆ Fake olasÄ±lÄ±k: {result['probabilities']['fake']:.3f}")
                print(f"   ğŸ“ˆ Real olasÄ±lÄ±k: {result['probabilities']['real']:.3f}")
            except Exception as e:
                print(f"   âŒ Tahmin hatasÄ±: {str(e)}")
        
    else:
        print("\nâŒ PIPELINE BAÅARISIZ!")
        return 1
    
    return 0

if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)